# Presentación (Ejemplo completoo) — Semanas 1 y 2 (Petstore)

---

## Slide 1 — Semana 1 (Pregunta 1 + Respuesta 1)
**Pregunta 1:** ¿Qué tipo de evidencia de pruebas reduce incertidumbre sobre calidad sin confundir “testing” con “quality assurance”?

**Respuesta 1:**
- Agregar aqui respuesta grupal (1/2 párrafos)

**Evidencia S1 (con oráculo + archivo):**
- Contrato accesible: **OpenAPI disponible**  
  - Oráculo: HTTP 200 + contiene `"openapi"`  
  - Evidencia: `evidence/week2/openapi.json`
- Operación básica: **Inventario responde**  
  - Oráculo: HTTP 200 + JSON bien formado  
  - Evidencia: `evidence/week2/inventory.json`
- Manejo mínimo de error: **endpoint inexistente**  
  - Oráculo: HTTP 404  
  - Evidencia: (registro en el log del script o captura del código)
- Tiempo preliminar local (baseline):  
  - Oráculo: registrar `time_total` (sin afirmar producción)  
  - Evidencia: `evidence/week2/latency_summary.txt`

**Límite (clave):**  
- “Esta evidencia no prueba seguridad ni ausencia de defectos; solo reduce incertidumbre sobre disponibilidad/contrato/operación mínima en entorno local.”

---

## Slide 2 — Semana 2 (Pregunta 2 + Respuesta 2)
**Pregunta 2:** ¿Cómo convertir “calidad” en afirmaciones falsables y medibles?

**Respuesta 2:**
- Agregar aqui respuesta grupal (1/2 párrafos)

**2 escenarios estrella (de `quality/scenarios.md`):**
- **Escenario A — Latencia básica de inventario (Performance local)**  
  - Estímulo: GET `/api/v3/store/inventory`  
  - Entorno: local, Docker, 30 repeticiones consecutivas  
  - Respuesta: HTTP 200 + JSON  
  - Medida: `time_total` por corrida (y p95 reportado)  
  - Evidencia: `evidence/week2/latency.csv` + `evidence/week2/latency_summary.txt`  
  - Falsación: tiempos exceden umbral propuesto o falla HTTP 200
- **Escenario B — Robustez ante IDs inválidos en `/pet/{id}`**  
  - Estímulo: IDs inválidos (-1, 0, 999999, abc)  
  - Entorno: local, sin carga, 1 ejecución por caso  
  - Respuesta: no retornar 200 para entradas inválidas  
  - Medida: `http_code` por caso  
  - Evidencia: `evidence/week2/invalid_ids.csv` + `evidence/week2/pet_<id>.json`  
  - Falsación: si algún caso devuelve HTTP 200, el escenario queda refutado

**Mini-tabla (Claim→Escenario→Métrica→Evidencia→Oráculo):**

| Claim | Escenario | Métrica | Evidencia (archivo) | Oráculo (pass/fail) |
|---|---|---|---|---|
| Contrato accesible | Q1 Contract Availability | HTTP + contiene `"openapi"` | `evidence/week2/openapi.json`, `openapi_http_code.txt` | pass si `200` y contiene `"openapi"` |
| Tiempo local preliminar | Q2 Latencia inventario (30 runs) | `time_total` por run (p95) | `evidence/week2/latency.csv`, `latency_summary.txt` | pass si HTTP 200 + (opcional) p95<=X |
| Entradas inválidas no aceptadas | Q3 Robustez IDs inválidos | `http_code` por caso | `evidence/week2/invalid_ids.csv`, `invalid_pet_<id>.json` | pass si todos `http_code != 200` |

---

## Slide 3 — Método formalizado
1) Definimos claims acotados (disponibilidad mínima, robustez, baseline de latencia).  
2) Los expresamos como escenarios (E–Entorno–R–Medida) en `quality/scenarios.md`.  
3) Definimos oráculos mínimos (HTTP 200/404, JSON válido, HTTP != 200).  
4) Generamos evidencia reproducible con scripts y la versionamos en `evidence/week1` y `evidence/week2`.

**Fuentes para definición de método:**
- ISTQB: oráculo y objetivos de prueba (criterio de pass/fail).  
- SWE@Google: testing como reducción de riesgo y claridad de pruebas.  
- arc42/ATAM: escenarios medibles y verificables (no adjetivos).

---

## Slide 4 — Validez (amenazas y límites)
- **Interna:** warm-up/caché del contenedor afecta latencia → Mitigación: descartar primeras N corridas o reiniciar antes de medir.  
- **Constructo:** latencia local es proxy (no producción) → Mitigación: declarar el alcance “local baseline” y no extrapolar.  
- **Externa:** resultados dependen de máquina/red → Mitigación: registrar entorno (CPU/RAM/Docker) y repetir en otra máquina.  

---

## Slide 5 — Cierre (2 conclusiones)
- **Evidencia más fuerte:** robustez IDs inválidos (falsación directa: un 200 refuta el escenario).  
- **Límite más crítico:** mediciones locales no generalizan a producción (validez externa).  
- **Mejora concreta (sin implementar hoy):** definir umbral explícito y justificarlo (p95<=X) documentando entorno.

---
